{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96abc40-3ba9-413a-9dca-9291f2e6b40e",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of \n",
    "> the options exactly. That's fine. \n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d4cff5-882a-42b2-8c30-02748c8f6453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:07.340541Z",
     "iopub.status.busy": "2025-10-20T18:24:07.339118Z",
     "iopub.status.idle": "2025-10-20T18:24:12.014039Z",
     "shell.execute_reply": "2025-10-20T18:24:12.013001Z",
     "shell.execute_reply.started": "2025-10-20T18:24:07.340497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5daa0897-9e27-4c40-8f36-541ba46e3d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:12.016802Z",
     "iopub.status.busy": "2025-10-20T18:24:12.016266Z",
     "iopub.status.idle": "2025-10-20T18:24:12.026131Z",
     "shell.execute_reply": "2025-10-20T18:24:12.023551Z",
     "shell.execute_reply.started": "2025-10-20T18:24:12.016775Z"
    }
   },
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed7dd4a-e673-497c-ace9-9f866f05d718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:12.038748Z",
     "iopub.status.busy": "2025-10-20T18:24:12.037637Z",
     "iopub.status.idle": "2025-10-20T18:24:12.915289Z",
     "shell.execute_reply": "2025-10-20T18:24:12.914424Z",
     "shell.execute_reply.started": "2025-10-20T18:24:12.038554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-20 20:24:12--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "185.199.108.133, 185.199.111.133, 185.199.110.133, ...tent.com)... \n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K   458KB/s    in 0.2s    \n",
      "\n",
      "2025-10-20 20:24:12 (458 KB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget $data -O course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be0aab4-aea6-4076-b404-d8480c061ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:12.917447Z",
     "iopub.status.busy": "2025-10-20T18:24:12.916940Z",
     "iopub.status.idle": "2025-10-20T18:24:12.967113Z",
     "shell.execute_reply": "2025-10-20T18:24:12.966436Z",
     "shell.execute_reply.started": "2025-10-20T18:24:12.917418Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8810898-2f6a-492b-b31d-68a20758207a",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For caterogiral features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 \n",
    "\n",
    "\n",
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` function for that with `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca215ba1-04cc-41b4-8b48-a520dd0d265d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:12.968804Z",
     "iopub.status.busy": "2025-10-20T18:24:12.968299Z",
     "iopub.status.idle": "2025-10-20T18:24:13.083945Z",
     "shell.execute_reply": "2025-10-20T18:24:13.083220Z",
     "shell.execute_reply.started": "2025-10-20T18:24:12.968771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after replacement:\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n",
      "\n",
      "Dataset split sizes:\n",
      "Train: (876, 8)\n",
      "Validation: (293, 8)\n",
      "Test: (293, 8)\n"
     ]
    }
   ],
   "source": [
    "# Separate columns by type\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Replace missing values\n",
    "df[categorical_cols] = df[categorical_cols].fillna('NA')\n",
    "df[numeric_cols] = df[numeric_cols].fillna(0.0)\n",
    "\n",
    "# Confirm that there are no more missing values\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Define features (X) and target (y) # Target: 'converted' → 1 if signed up, 0 otherwise\n",
    "X = df.drop(columns=['converted'])\n",
    "y = df['converted']\n",
    "\n",
    "# Split the dataset, First split into 80% train, 20% temp\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Then split temp into 20% validation and 20% test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=1)\n",
    "\n",
    "# reset Index\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nDataset split sizes:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Validation: {X_val.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4011e-1ba7-4d52-b12f-457f0c02bbb4",
   "metadata": {},
   "source": [
    "### Question 1: ROC AUC feature importance\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score (aka prediction) and compute the AUC with the `y` variable as ground truth.\n",
    "* Use the training dataset for that\n",
    "\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['balance']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- `lead_score`\n",
    "- `number_of_courses_viewed`\n",
    "- `interaction_count`\n",
    "- `annual_income`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a2384-e004-490e-a7a0-7c8b7dd4f609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:01.878951Z",
     "iopub.status.busy": "2025-10-15T15:40:01.877557Z",
     "iopub.status.idle": "2025-10-15T15:40:01.888573Z",
     "shell.execute_reply": "2025-10-15T15:40:01.886721Z",
     "shell.execute_reply.started": "2025-10-15T15:40:01.878910Z"
    }
   },
   "source": [
    "actual_positive = (y_val == 1)\n",
    "actual_negative = (y_val == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740afa04-e33e-4049-b549-91f78068ae91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:01.896903Z",
     "iopub.status.busy": "2025-10-15T15:40:01.895484Z",
     "iopub.status.idle": "2025-10-15T15:40:01.906949Z",
     "shell.execute_reply": "2025-10-15T15:40:01.904236Z",
     "shell.execute_reply.started": "2025-10-15T15:40:01.896866Z"
    }
   },
   "source": [
    "t = 0.5\n",
    "predict_positive = (y_pred >= t)\n",
    "predict_negative = (y_pred < t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfffe722-778e-4e9b-ad2d-ef25bffc7b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:01.910955Z",
     "iopub.status.busy": "2025-10-15T15:40:01.908736Z",
     "iopub.status.idle": "2025-10-15T15:40:01.924049Z",
     "shell.execute_reply": "2025-10-15T15:40:01.919469Z",
     "shell.execute_reply.started": "2025-10-15T15:40:01.910917Z"
    }
   },
   "source": [
    "tp = (predict_positive & actual_positive).sum()\n",
    "tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "fp = (predict_positive & actual_negative).sum()\n",
    "fn = (predict_negative & actual_positive).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023278aa-697c-4da4-8571-848a4bbfb73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:01.938835Z",
     "iopub.status.busy": "2025-10-15T15:40:01.938381Z",
     "iopub.status.idle": "2025-10-15T15:40:01.963901Z",
     "shell.execute_reply": "2025-10-15T15:40:01.961861Z",
     "shell.execute_reply.started": "2025-10-15T15:40:01.938804Z"
    }
   },
   "source": [
    "# Precision & Recall\n",
    "p = tp / (tp + fp)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df006748-bbc1-475e-9dc4-bb9ba25c8302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:01.968778Z",
     "iopub.status.busy": "2025-10-15T15:40:01.965850Z",
     "iopub.status.idle": "2025-10-15T15:40:01.985267Z",
     "shell.execute_reply": "2025-10-15T15:40:01.982012Z",
     "shell.execute_reply.started": "2025-10-15T15:40:01.968730Z"
    }
   },
   "source": [
    "r = tp / (tp + fn)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f5a8f-5997-4fda-a00f-bc00db6fce47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:01.987781Z",
     "iopub.status.busy": "2025-10-15T15:40:01.987074Z",
     "iopub.status.idle": "2025-10-15T15:40:02.005096Z",
     "shell.execute_reply": "2025-10-15T15:40:02.002615Z",
     "shell.execute_reply.started": "2025-10-15T15:40:01.987748Z"
    }
   },
   "source": [
    "#ROC Curves TPR and FRP\n",
    "tpr = tp / (tp + fn)\n",
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6a69c-736b-4816-9106-3bcec611d1a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:02.011326Z",
     "iopub.status.busy": "2025-10-15T15:40:02.007702Z",
     "iopub.status.idle": "2025-10-15T15:40:02.071352Z",
     "shell.execute_reply": "2025-10-15T15:40:02.064376Z",
     "shell.execute_reply.started": "2025-10-15T15:40:02.011272Z"
    }
   },
   "source": [
    "fpr = fp / (fp + tn)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27453dd3-3869-4799-8ec8-8cba3428b7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:02.147298Z",
     "iopub.status.busy": "2025-10-15T15:40:02.146063Z",
     "iopub.status.idle": "2025-10-15T15:40:02.162609Z",
     "shell.execute_reply": "2025-10-15T15:40:02.159253Z",
     "shell.execute_reply.started": "2025-10-15T15:40:02.147262Z"
    }
   },
   "source": [
    "scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2875f6-689b-45ab-a6c1-68845e30a958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:02.167672Z",
     "iopub.status.busy": "2025-10-15T15:40:02.163809Z",
     "iopub.status.idle": "2025-10-15T15:40:02.186846Z",
     "shell.execute_reply": "2025-10-15T15:40:02.185115Z",
     "shell.execute_reply.started": "2025-10-15T15:40:02.167628Z"
    }
   },
   "source": [
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98614b-305e-4c7c-9b5d-6a7f47f2d6da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T15:40:02.188758Z",
     "iopub.status.busy": "2025-10-15T15:40:02.188181Z",
     "iopub.status.idle": "2025-10-15T15:40:02.496529Z",
     "shell.execute_reply": "2025-10-15T15:40:02.494751Z",
     "shell.execute_reply.started": "2025-10-15T15:40:02.188724Z"
    }
   },
   "source": [
    "plt.plot(df_scores.threshold, df_scores['tpr'], label='TPR')\n",
    "plt.plot(df_scores.threshold, df_scores['fpr'], label='FPR')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9288e5-3de8-47af-a191-8df0cf1eb03d",
   "metadata": {},
   "source": [
    "ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e8ebe6-f31c-44cf-9b42-203b918358fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:13.090782Z",
     "iopub.status.busy": "2025-10-20T18:24:13.090496Z",
     "iopub.status.idle": "2025-10-20T18:24:13.132794Z",
     "shell.execute_reply": "2025-10-20T18:24:13.130646Z",
     "shell.execute_reply.started": "2025-10-20T18:24:13.090762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_score: AUC = 0.61\n",
      "number_of_courses_viewed: AUC = 0.76\n",
      "interaction_count: AUC = 0.74\n",
      "annual_income: AUC = 0.55\n",
      "\n",
      "The numerical variable with the highest AUC is: number_of_courses_viewed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df_train = X_train.copy()\n",
    "df_train['converted'] = y_train\n",
    "\n",
    "numeric_features = [\n",
    "    'lead_score',\n",
    "    'number_of_courses_viewed',\n",
    "    'interaction_count',\n",
    "    'annual_income'\n",
    "]\n",
    "\n",
    "auc_scores = {}\n",
    "\n",
    "for feature in numeric_features:\n",
    "    # Compute ROC AUC using this feature as the score\n",
    "    auc = roc_auc_score(y_train, df_train[feature])\n",
    "    \n",
    "    # If AUC < 0.5, invert the variable\n",
    "    if auc < 0.5:\n",
    "        auc = roc_auc_score(y_train, -df_train[feature])\n",
    "        print(f\"{feature}: inverted (original AUC < 0.5)\")\n",
    "    \n",
    "    auc_scores[feature] = auc\n",
    "    print(f\"{feature}: AUC = {auc:.2f}\")\n",
    "\n",
    "# Find the variable with the highest AUC\n",
    "best_feature = max(auc_scores, key=auc_scores.get)\n",
    "print(\"\\nThe numerical variable with the highest AUC is:\", best_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296695d3-16b6-402f-b527-896896c30c6a",
   "metadata": {},
   "source": [
    "### Question 2: Training the model\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```python\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.32\n",
    "- 0.52\n",
    "- 0.72\n",
    "- 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2dbdc1-08f9-41d2-a307-e61e52b8aedf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:36:31.165527Z",
     "iopub.status.busy": "2025-10-20T18:36:31.164839Z",
     "iopub.status.idle": "2025-10-20T18:36:31.429609Z",
     "shell.execute_reply": "2025-10-20T18:36:31.427552Z",
     "shell.execute_reply.started": "2025-10-20T18:36:31.165461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# X_train_enc → das Ergebnis, das vollständig numerisch ist, sodass der LogisticRegression-Algorithmus es verarbeiten kann\n",
    "X_train_enc = dv.fit_transform(X_train.to_dict(orient='records'))\n",
    "X_val_enc = dv.transform(X_val.to_dict(orient='records'))\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train_enc, y_train)\n",
    "\n",
    "# Predict probabilities and compute AUC\n",
    "y_pred_val = model.predict_proba(X_val_enc)[:, 1]\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "\n",
    "print(f\"Validation AUC: {auc_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d019c-f25d-40e5-8ff2-f08e7bc3566a",
   "metadata": {},
   "source": [
    "### Question 3: Precision and Recall\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.145\n",
    "* 0.345\n",
    "* 0.545\n",
    "* 0.745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09519385-1ccf-46fc-80b8-56ec53bff90e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:24:13.237784Z",
     "iopub.status.busy": "2025-10-20T18:24:13.237351Z",
     "iopub.status.idle": "2025-10-20T18:24:13.264129Z",
     "shell.execute_reply": "2025-10-20T18:24:13.262761Z",
     "shell.execute_reply.started": "2025-10-20T18:24:13.237761Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0080c48d-75c6-465b-9c5f-6c9a00d54dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:33.321735Z",
     "iopub.status.busy": "2025-10-20T18:43:33.321388Z",
     "iopub.status.idle": "2025-10-20T18:43:33.897494Z",
     "shell.execute_reply": "2025-10-20T18:43:33.896606Z",
     "shell.execute_reply.started": "2025-10-20T18:43:33.321711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection threshold: 0.640\n"
     ]
    }
   ],
   "source": [
    "# Thresholds\n",
    "thresholds = np.linspace(start=0.0, stop=1.0, num=101)\n",
    "\n",
    "# Scores\n",
    "scores = []\n",
    "\n",
    "# Evaluate thresholds\n",
    "for t in thresholds:\n",
    "    # Apply threshold to get binary prediction\n",
    "    y_val_binary = (y_pred_val >= t).astype(int)\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    p = precision_score(y_val, y_val_binary, zero_division=0)\n",
    "    r = recall_score(y_val, y_val_binary)\n",
    "\n",
    "    scores.append((t, p, r))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, columns=[\"threshold\", \"precision\", \"recall\"])\n",
    "\n",
    "# Absolute difference between precision and recall\n",
    "df_scores[\"pr_diff\"] = np.abs(df_scores[\"precision\"] - df_scores[\"recall\"])\n",
    "\n",
    "# Find the threshold where this difference is minimal\n",
    "intersection_threshold = (\n",
    "    df_scores.query(\"precision != 0 & recall != 0\")\n",
    "    .sort_values(by=\"pr_diff\")\n",
    "    .head(1)[\"threshold\"]\n",
    "    .values[0]\n",
    ")\n",
    "\n",
    "print(f\"Intersection threshold: {intersection_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd89e9e-5435-495e-8991-a6ebd1cf7733",
   "metadata": {},
   "source": [
    "Intersection ≈ 0.345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ecde28-4844-4ff8-b539-1ff39e0e5e14",
   "metadata": {},
   "source": [
    "### Question 4: F1 score\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.14\n",
    "- 0.34\n",
    "- 0.54\n",
    "- 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932ded1a-98e7-4409-92a9-8770ba7cddc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:34.790453Z",
     "iopub.status.busy": "2025-10-20T18:43:34.789688Z",
     "iopub.status.idle": "2025-10-20T18:43:35.521974Z",
     "shell.execute_reply": "2025-10-20T18:43:35.519947Z",
     "shell.execute_reply.started": "2025-10-20T18:43:34.790408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 occurs at threshold ≈ 0.57\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "f1_scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_thresh = (y_pred_val >= t).astype(int)\n",
    "    p = precision_score(y_val, y_pred_thresh, zero_division=0)\n",
    "    r = recall_score(y_val, y_pred_thresh)\n",
    "    if p + r == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (p * r) / (p + r)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "f1_scores = np.array(f1_scores)\n",
    "\n",
    "# Find threshold where F1 is maximal\n",
    "idx_max_f1 = np.argmax(f1_scores)\n",
    "threshold_max_f1 = thresholds[idx_max_f1]\n",
    "\n",
    "print(f\"Maximum F1 occurs at threshold ≈ {threshold_max_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bc908-1f1f-4241-8a36-be30328a33ea",
   "metadata": {},
   "source": [
    "### Question 5: 5-Fold CV\n",
    "\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard deviation of the scores across different folds?\n",
    "\n",
    "- 0.0001\n",
    "- 0.006\n",
    "- 0.06\n",
    "- 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc918a3-5ea8-4461-ad40-56ffa7eb6752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:35.534432Z",
     "iopub.status.busy": "2025-10-20T18:43:35.524692Z",
     "iopub.status.idle": "2025-10-20T18:43:35.745469Z",
     "shell.execute_reply": "2025-10-20T18:43:35.744350Z",
     "shell.execute_reply.started": "2025-10-20T18:43:35.534381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores across folds: [0.8172202350536536, 0.7792846497764531, 0.8309278350515464, 0.8675988428158148, 0.8093413173652695]\n",
      "Mean AUC: 0.821\n",
      "Standard deviation of AUC: 0.029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Assume df_full_train is your training dataset (after cleaning, missing values handled)\n",
    "# and target is 'converted'\n",
    "\n",
    "df_full_train = df.copy() \n",
    "\n",
    "X_full_train = df_full_train.drop(columns=['converted'])\n",
    "y_full_train = df_full_train['converted']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_full_train):\n",
    "    X_train_fold, X_val_fold = X_full_train.iloc[train_index], X_full_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_full_train.iloc[train_index], y_full_train.iloc[val_index]\n",
    "    \n",
    "    # One-hot encoding using DictVectorizer\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train_enc = dv.fit_transform(X_train_fold.to_dict(orient='records'))\n",
    "    X_val_enc = dv.transform(X_val_fold.to_dict(orient='records'))\n",
    "    \n",
    "    # Train logistic regression\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(X_train_enc, y_train_fold)\n",
    "    \n",
    "    # Predict probabilities and compute AUC\n",
    "    y_pred_val = model.predict_proba(X_val_enc)[:, 1]\n",
    "    auc = roc_auc_score(y_val_fold, y_pred_val)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "auc_mean = np.mean(auc_scores)\n",
    "auc_std = np.std(auc_scores)\n",
    "\n",
    "print(f\"AUC scores across folds: {auc_scores}\")\n",
    "print(f\"Mean AUC: {auc_mean:.3f}\")\n",
    "print(f\"Standard deviation of AUC: {auc_std:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77bc85-3eff-4d98-8c15-fea44401c5fb",
   "metadata": {},
   "source": [
    "### Question 6: Hyperparameter Tuning\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter `C`\n",
    "\n",
    "* Iterate over the following `C` values: `[0.000001, 0.001, 1]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parameters for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which `C` leads to the best mean score?\n",
    "\n",
    "- 0.000001\n",
    "- 0.001\n",
    "- 1\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd7efea-f1d7-412e-a857-714f44727d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T18:43:36.664432Z",
     "iopub.status.busy": "2025-10-20T18:43:36.664025Z",
     "iopub.status.idle": "2025-10-20T18:43:37.175586Z",
     "shell.execute_reply": "2025-10-20T18:43:37.174118Z",
     "shell.execute_reply.started": "2025-10-20T18:43:36.664404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1e-06: Mean AUC=0.549, Std=0.03\n",
      "C=0.001: Mean AUC=0.862, Std=0.024\n",
      "C=1: Mean AUC=0.821, Std=0.029\n",
      "\n",
      "Best C according to CV: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Use the cleaned full training dataset\n",
    "X_full_train = df_full_train.drop(columns=['converted'])\n",
    "y_full_train = df_full_train['converted']\n",
    "\n",
    "# Hyperparameter candidates\n",
    "C_values = [0.000001, 0.001, 1]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "results = []\n",
    "\n",
    "for C in C_values:\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_full_train):\n",
    "        X_train_fold, X_val_fold = X_full_train.iloc[train_index], X_full_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_full_train.iloc[train_index], y_full_train.iloc[val_index]\n",
    "        \n",
    "        # One-hot encoding\n",
    "        dv = DictVectorizer(sparse=False)\n",
    "        X_train_enc = dv.fit_transform(X_train_fold.to_dict(orient='records'))\n",
    "        X_val_enc = dv.transform(X_val_fold.to_dict(orient='records'))\n",
    "        \n",
    "        # Train logistic regression\n",
    "        model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "        model.fit(X_train_enc, y_train_fold)\n",
    "        \n",
    "        y_pred_val = model.predict_proba(X_val_enc)[:, 1]\n",
    "        auc = roc_auc_score(y_val_fold, y_pred_val)\n",
    "        auc_scores.append(auc)\n",
    "    \n",
    "    mean_auc = np.round(np.mean(auc_scores), 3)\n",
    "    std_auc = np.round(np.std(auc_scores), 3)\n",
    "    results.append((C, mean_auc, std_auc))\n",
    "    print(f\"C={C}: Mean AUC={mean_auc}, Std={std_auc}\")\n",
    "\n",
    "# Select best C\n",
    "# First, highest mean. If tie, lowest std. If still tie, smallest C.\n",
    "results_sorted = sorted(results, key=lambda x: (-x[1], x[2], x[0]))\n",
    "best_C = results_sorted[0][0]\n",
    "print(f\"\\nBest C according to CV: {best_C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632ccf1-88b6-4f03-b697-779f227807e1",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw04\n",
    "* If your answer doesn't match options exactly, select the closest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964fa1ab-0008-40b5-87be-bbf4285dfd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
